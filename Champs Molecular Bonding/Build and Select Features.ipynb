{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is loosely based on ideas from \n",
    "\n",
    "* https://www.kaggle.com/xwxw2929/keras-neural-net-and-distance-features\n",
    "* https://www.kaggle.com/todnewman/keras-neural-net-for-champs\n",
    "* https://www.kaggle.com/criskiev/distance-is-all-you-need-lb-1-481\n",
    "* https://www.kaggle.com/abazdyrev/nn-w-o-skew\n",
    "* https://www.kaggle.com/marcogorelli/criskiev-s-distances-more-estimators-groupkfold\n",
    "* https://www.kaggle.com/inversion/atomic-distance-benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/timestocome/Kaggle\n",
    "### https://www.kaggle.com/c/champs-scalar-coupling\n",
    "\n",
    "### Goal: improve prediction of scalar coupling constant using only provided dataset\n",
    "### This kernel is used to evaluate features - it grossly overfits on submission data\n",
    "\n",
    "####  Improvements\n",
    "* added feature importance plots\n",
    "* added plts of predicted vs actual in validation data\n",
    "* added functions to calculate VanDerWaals, Coulomb, Yukawa forces\n",
    "* cleaned and improved db manipulations, more could be done\n",
    "\n",
    "* this ML was just used as a feature selector. The data isn't really suitable for a tree algorithm\n",
    "\n",
    "\n",
    "* Best possible score ~ -20\n",
    "* Winning score -3.2\n",
    "* My best -1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in raw datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv', index_col=0)\n",
    "\n",
    "# remove batch name from molecule id\n",
    "train['molecule_index'] = train.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train.drop(['molecule_name'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "coupling_types = sorted(train['type'].unique())\n",
    "\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Data/test.csv', index_col=0)\n",
    "\n",
    "\n",
    "# remove batch name from molecule id\n",
    "test['molecule_index'] = test.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test.drop(['molecule_name'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = pd.read_csv('Data/structures.csv')\n",
    "\n",
    "atomic_numbers = { 'H': 1, 'C':6, 'N':7, 'O':8, 'F': 9 }\n",
    "\n",
    "# https://www.thoughtco.com/element-charges-chart-603986\n",
    "atomic_chg = { 'H': 1, 'C': 4, 'N': -3, 'O': -2, 'F': -1 }\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Electronegativity\n",
    "atomic_pchgs = { 'H': 2.2, 'C': 2.55, 'N': 3.04, 'O': 3.44, 'F': 3.98 }\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Atomic_radius\n",
    "atomic_size = { 'H': 0.25, 'C': 0.7, 'N': 0.65, 'O': 0.60, 'F': 0.5 }\n",
    "\n",
    "\n",
    "# get atom count per molecule and merge back into struct\n",
    "u_atoms = struct.groupby(['molecule_name'])['atom'].value_counts()\n",
    "u_atoms = u_atoms.unstack()\n",
    "u_atoms = u_atoms.fillna(0)\n",
    "\n",
    "print(u_atoms.head(20))\n",
    "\n",
    "# get OxBalance\n",
    "u_atoms['total atoms'] = u_atoms['O'] + u_atoms['C'] + u_atoms['F'] + u_atoms['N'] + u_atoms['H']\n",
    "u_atoms['Ox balance'] = (u_atoms['O'] - 2*u_atoms['C'] - u_atoms['H']) / u_atoms['total atoms']\n",
    "\n",
    "struct = pd.merge(struct, u_atoms, how='left', left_on=['molecule_name'], right_on=['molecule_name'])\n",
    "\n",
    "\n",
    "\n",
    "# remove batch name from molecule id\n",
    "struct['molecule_index'] = struct.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "struct.drop(['molecule_name'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# swap out letter id for atoms with atomic_numbers\n",
    "#struct['atom'] = struct['atom'].replace(atomic_size)   # -.17\n",
    "#struct['atom'] = struct['atom'].replace(atomic_chg)   # -.25\n",
    "#struct['atom'] = struct['atom'].replace(atomic_pchgs)   # -.22\n",
    "struct['atom'] = struct['atom'].replace(atomic_numbers)   # -.25\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Data/sample_submission.csv', index_col='id')\n",
    "\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep data for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### split out data types and merge with location db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pull coupling datatype from train/test and structures dfs\n",
    "def fetch_type_data(df, struct, ctype):\n",
    "    \n",
    "    # pull out all rows with this coupling type from train data and make a copy\n",
    "    df = df[df['type'] == ctype].drop('type', axis=1).copy()\n",
    "    \n",
    "    # pull out all rows with this coupling type from structs\n",
    "    struct_df = struct[struct['molecule_index'].isin(df['molecule_index'])]\n",
    "    \n",
    "    \n",
    "    return df, struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge train/test with structs df\n",
    "def merge_coordinates(bonds, structures, index):\n",
    "    \n",
    "    df = pd.merge(bonds, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    \n",
    "    if index == 0:\n",
    "        df.drop(columns=['C', 'F', 'H', 'N', 'O', 'total atoms', 'Ox balance'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get distances between atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance between each atom \n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    \n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coulomb force distance between each atom \n",
    "\n",
    "# calculate coulomb force distance between each atom \n",
    "# 1/2 Z^2.4 if i!=j\n",
    "# Zi*Zj/|Ri - Rj|\n",
    "\n",
    "# atomic numbers should be used for atom\n",
    "def add_coulomb_between(df, suffix1, suffix2):\n",
    "    \n",
    "    \n",
    "    Zi = df[f'atom_{suffix1}']\n",
    "    Zj = df[f'atom_{suffix2}']\n",
    "    \n",
    "    \n",
    "    #df[f'c_sm_{suffix1}_{suffix2}'] = 0.5 * Zi**2.4\n",
    "        \n",
    "    df[f'c_df{suffix1}_{suffix2}'] = (Zi * Zj) / ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "         )**np.float32(0.5))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def add_coulombs(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_coulomb_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate  yukawa force distance between each atom \n",
    "\n",
    "def add_yuka_between(df, suffix1, suffix2):\n",
    "    \n",
    "    df[f'yk_{suffix1}_{suffix2}'] =  np.exp(-((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_yukas(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_yuka_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate vaderwaal's force distance between each atom \n",
    "def add_vander_between(df, suffix1, suffix2):\n",
    "    \n",
    "    df[f'v_{suffix1}_{suffix2}'] = 1./ ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_vanders(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_vander_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_df(df, structures, ctype, n_atoms):\n",
    "    \n",
    "    # fetch coupling type data from train/test and structs files\n",
    "    bonds, structs = fetch_type_data(df, struct, ctype)\n",
    "    \n",
    "    # merge structs and coupling data for atom col 0, 1\n",
    "    bonds = merge_coordinates(bonds, structs, 0)\n",
    "    bonds = merge_coordinates(bonds, structs, 1)\n",
    "   \n",
    "   \n",
    "    \n",
    "    # make a copy of df just built and drop target from training\n",
    "    atoms = bonds.copy()\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        atoms.drop(['scalar_coupling_constant'], axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "    # add center location between coupled atoms and drop xyz locations of each atom\n",
    "    atoms['x_c'] = ((atoms['x_1'] + atoms['x_0']) * np.float32(0.5))\n",
    "    atoms['y_c'] = ((atoms['y_1'] + atoms['y_0']) * np.float32(0.5))\n",
    "    atoms['z_c'] = ((atoms['z_1'] + atoms['z_0']) * np.float32(0.5))\n",
    "    \n",
    "    # add r\n",
    "    atoms['dx'] = ((atoms['x_1'] + atoms['x_0']) * np.float32(0.5))\n",
    "    atoms['dy'] = ((atoms['y_1'] + atoms['y_0']) * np.float32(0.5))\n",
    "    atoms['dz'] = ((atoms['z_1'] + atoms['z_0']) * np.float32(0.5))\n",
    "    atoms['r'] = np.sqrt(atoms['dx'] + atoms['dy'] + atoms['dz'])\n",
    "    atoms.drop(['dx', 'dy', 'dz'], axis=1, inplace=True)\n",
    "    \n",
    "    # drop location info\n",
    "    atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1, inplace=True)\n",
    "    \n",
    "    # merge location info back in\n",
    "    # this creates a row for each atom to all other atoms\n",
    "    atoms = pd.merge(atoms, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    \n",
    "    atoms.drop(columns=['C_x', 'F_x', 'H_x', 'N_x', 'O_x', 'total atoms_x', 'Ox balance_x'], inplace=True)\n",
    "    atoms = atoms.rename( columns={'C_y': 'C', 'F_y': 'F', 'H_y': 'H', 'N_y': 'N', 'O_y': 'O', \n",
    "                    'total atoms_y': 'total atoms', 'Ox balance_y': 'Ox balance'})\n",
    "\n",
    "   \n",
    "\n",
    "    # remove dups ?\n",
    "    atoms = atoms[(atoms.atom_index_0 != atoms.atom_index) & (atoms.atom_index_1 != atoms.atom_index)]\n",
    "    \n",
    "    # add distances for each atom to center of coupled pairs\n",
    "    atoms['d_c'] = ((\n",
    "        (atoms['x_c'] - atoms['x'])**np.float32(2) +\n",
    "        (atoms['y_c'] - atoms['y'])**np.float32(2) + \n",
    "        (atoms['z_c'] - atoms['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "    \n",
    "    \n",
    "    # remove center of coupled pairs\n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    \n",
    "    # sort by molecule, atom 0, atom 1 and distance to center of coupled pairs\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    \n",
    "    \n",
    "    # group and unstack.... https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n",
    "    # group atoms by molecule and atoms\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # count the number of atoms in molecule by distance from coupled pair\n",
    "    # and remove distance to center --- only needed for sort\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    \n",
    "    # remove rows that are greater than the max of nearby atoms wanted for \n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "        \n",
    "   \n",
    "    \n",
    "    # convert molecule id, atom 0, atom 1 into index columns\n",
    "    # this adds cols for each atom up to n_atoms, and x, y, z for each atom that is kept\n",
    "    # relabel new columns and fix index\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "\n",
    "    \n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()  \n",
    "    \n",
    "     # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # more cleanup\n",
    "    x_cols = [z for z in atoms.columns if z.startswith('x_')]\n",
    "    y_cols = [z for z in atoms.columns if z.startswith('y_')]\n",
    "    z_cols = [z for z in atoms.columns if z.startswith('z_')]\n",
    "    a_cols = [z for z in atoms.columns if z.startswith('atom_')]\n",
    "    atoms = atoms.rename( columns={'C_2': 'C', 'F_2': 'F', 'H_2': 'H', 'N_2': 'N', 'O_2': 'O', \n",
    "                    'total atoms_2': 'total atoms', 'Ox balance_2': 'Ox balance'})\n",
    "    \n",
    "    misc_features = ['molecule_index', #'atom_index_0', 'atom_index_1', \n",
    "                     'C', 'F', 'H', 'N', 'O', 'total atoms', 'Ox balance']\n",
    "    keep_cols = x_cols + y_cols + z_cols + a_cols + misc_features\n",
    "    \n",
    "    \n",
    "    atoms = atoms[keep_cols]\n",
    "    \n",
    "   \n",
    "   \n",
    "    # merge it all back together into coupling df\n",
    "    df = pd.merge(bonds, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    \n",
    "    \n",
    "    df = df.rename( columns={'C_y': 'C', 'F_y': 'F', 'H_y': 'H', 'N_y': 'N', 'O_y': 'O', \n",
    "                    'total atoms_y': 'total atoms', 'Ox balance_y': 'Ox balance'})\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    # calculate distances from x,y,z of each atom and cleanup\n",
    "    add_distances(df)\n",
    "    add_coulombs(df)\n",
    "    add_yukas(df)\n",
    "    add_vanders(df)\n",
    "\n",
    "      \n",
    "    df = df.fillna(0)\n",
    "    df.drop(columns=['atom_index_0', 'atom_index_1'], inplace=True)\n",
    "    df.drop(['atom_0', 'atom_1'], axis=1, inplace=True)\n",
    "    \n",
    "    x_col0 = df.columns[df.columns.str.startswith('atom_0')]\n",
    "    x_col1 = df.columns[df.columns.str.startswith('atom_1')]\n",
    "    \n",
    "    df.drop(x_col0, axis=1, inplace=True)\n",
    "    df.drop(x_col1, axis=1, inplace=True)\n",
    "    \n",
    "   \n",
    "    df['N/C'] = df['N'] / df['C']\n",
    "    df['O/C'] = df['O'] / df['C']\n",
    "    df['H/C'] = df['H'] / df['C']\n",
    "    df['N-O'] = df['N'] - df['O']\n",
    "    df['C-N'] = df['C'] - df['N']\n",
    "    df['C-F'] = df['C'] - df['F']\n",
    "    df['C-N-H'] = df['C'] - df['N'] - df['H']\n",
    "    df['C-N*O -C*N'] = df['C'] - df['N']*df['O'] - df['C']*df['N']\n",
    "    \n",
    "   \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check predicted against actual - perfect score is line at 45'\n",
    "# scores alone don't contain enough information, \n",
    "#   eyeball predicted validation against actual validation\n",
    "#   can show trouble spots, outlier problems....\n",
    "\n",
    "def plot_output(actual, predicted, coupling_type):\n",
    "  \n",
    "    print('plotting output', actual.shape, predicted.shape, coupling_type)\n",
    "  \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plt.xlim(actual.min(), actual.max())\n",
    "    plt.ylim(actual.min(), actual.max())\n",
    "\n",
    "    plt.scatter(actual, predicted)\n",
    "    plt.title(coupling_type)\n",
    "    plt.grid(True)\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ashishpatel26/feature-importance-of-lightgbm\n",
    "def plot_features(feature_imp):\n",
    "    \n",
    "    # sorted(zip(clf.feature_importances_, X.columns), reverse=True)\n",
    "    #feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10, 30))\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "    plt.title('LightGBM Features')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_and_split_data(some_csv, coupling_type, n_atoms):\n",
    "    \n",
    "    df = build_df(some_csv, struct, coupling_type, n_atoms=n_atoms)\n",
    "        \n",
    "    molecule_index = df['molecule_index'].values\n",
    "    df.drop('molecule_index', axis=1, inplace=True)\n",
    "    \n",
    "         \n",
    "    # features\n",
    "    #atom_features = [z for z in df.columns if z.startswith('atom_')]\n",
    "    distance_features = [z for z in df.columns if z.startswith('d_')]\n",
    "    coulomb_features = [z for z in df.columns if z.startswith('c_')]\n",
    "    vanderwaal_features = [z for z in df.columns if z.startswith('v_')]\n",
    "    #yuka_features = [z for z in df.columns if z.startswith('yk_')]\n",
    "    #misc_features = ['C', 'F', 'H', 'N', 'O', 'total atoms', 'Ox balance']\n",
    "    #bond_features = ['N/C', 'O/C', 'H/C', 'N-O', 'C-N', 'C-F', 'C-N-H', 'C-N*O -C*N']\n",
    "\n",
    "    misc_features = ['H', 'total atoms', 'Ox balance']\n",
    "    bond_features = ['N/C', 'O/C', 'H/C', 'N-O', 'C-N-H', 'C-N*O -C*N']\n",
    "    \n",
    "    features = coulomb_features + vanderwaal_features  + misc_features + bond_features\n",
    "    #features = atom_features + distance_features\n",
    "    \n",
    "        \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "        X_data = df[features].values.astype('float32')\n",
    "\n",
    "    else:\n",
    "        X_data = df[features].values.astype('float32')\n",
    "        y_data = None\n",
    "       \n",
    "    \n",
    "    print(X_data.shape)\n",
    "    \n",
    "    return X_data, y_data, molecule_index, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration params are copied from @artgor kernel:\n",
    "# https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 128,\n",
    "    'max_depth': 7,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "\n",
    "n_estimators = 2048\n",
    "early_stopping = 32\n",
    "\n",
    "model_params = {\n",
    "    '1JHC': 14,\n",
    "    '1JHN': 7,\n",
    "    '2JHC': 14,\n",
    "    '2JHH': 12,\n",
    "    '2JHN': 12,\n",
    "    '3JHC': 14,\n",
    "    '3JHH': 9,\n",
    "    '3JHN': 12\n",
    "}\n",
    "\n",
    "\n",
    "N_FOLDS = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict (coupling_type, submission, n_atoms, n_folds=5, n_splits=5):\n",
    "    \n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data, groups, features = build_and_split_data(train, coupling_type, n_atoms)\n",
    "    X_test, _, _, _ = build_and_split_data(test, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "    \n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data, groups=groups)):\n",
    "        \n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "        model = LGBMRegressor(**LGB_PARAMS, n_estimators=n_estimators, n_jobs = -1)\n",
    "        \n",
    "        model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mse',\n",
    "            verbose=100, early_stopping_rounds=early_stopping)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        \n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        \n",
    "        plot_output(y_val, y_val_pred, coupling_type)\n",
    "        \n",
    "        feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_, features)), \n",
    "                               columns=['Value','Feature'])\n",
    "        plot_features(feature_imp)\n",
    "        \n",
    "        \n",
    "        cv_score += val_score\n",
    "        y_pred += model.predict(X_test)\n",
    "        \n",
    "         \n",
    "        break \n",
    "    \n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# loop over coupling types, build df, train model, get predictions\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in coupling_types:\n",
    "    \n",
    "    cv_score = train_and_predict(\n",
    "        coupling_type, submission, n_atoms = model_params[coupling_type], n_folds=N_FOLDS)\n",
    " \n",
    "    cv_scores[coupling_type] = cv_score\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model accuracy\n",
    "\n",
    "\n",
    "print( pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())}) )\n",
    "print( np.mean(list(cv_scores.values())) )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
